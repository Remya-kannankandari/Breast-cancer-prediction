{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer_data = load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "dataset = load_breast_cancer()\n",
    "features = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "labels = pd.Series(dataset.target)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Save the dataframes to CSV files\n",
    "X_train.to_csv('train_features.csv', index=False)\n",
    "X_test.to_csv('test_features.csv', index=False)\n",
    "y_train.to_csv('train_labels.csv', index=False)\n",
    "y_test.to_csv('test_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['mean radius', 'mean perimeter', 'mean area', 'mean concavity',\n",
      "       'mean concave points', 'worst radius', 'worst perimeter', 'worst area',\n",
      "       'worst concavity', 'worst concave points'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the feature selection\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=10)  # Select top 10 features\n",
    "selected_features = feature_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "selected_columns = X_train.columns[feature_selector.get_support()]\n",
    "print(\"Selected Features:\", selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the ANN model\n",
    "ann_model = MLPClassifier(max_iter=1000)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "# Set up Grid Search with Cross-Validation\n",
    "grid_search_cv = GridSearchCV(estimator=ann_model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_search_results = grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by Grid Search\n",
    "print(f\"Optimal Parameters: {grid_search_results.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.9708\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        63\n",
      "           1       0.96      1.00      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.98      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Retrieve the best parameters from Grid Search\n",
    "best_params = grid_search_results.best_params_\n",
    "best_ann_model = MLPClassifier(**best_params, max_iter=1000)\n",
    "best_ann_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = best_ann_model.predict(X_test)\n",
    "print(f\"Accuracy on Test Data: {accuracy_score(y_test, predictions):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.37.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.4.0)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (9.5.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.25.4)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.4)\n",
      "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-4.0.1-py3-none-win_amd64.whl.metadata (37 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.5.7)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.37.1-py2.py3-none-any.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/8.7 MB 1.7 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.2/8.7 MB 2.2 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/8.7 MB 3.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.1/8.7 MB 6.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.3/8.7 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.7/8.7 MB 15.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.0/8.7 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.6/8.7 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 21.3 MB/s eta 0:00:00\n",
      "Using cached altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading pyarrow-17.0.0-cp311-cp311-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.9/25.2 MB 124.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.5/25.2 MB 96.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/25.2 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/25.2 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.3/25.2 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.9/25.2 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.2 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 73.0 MB/s eta 0:00:00\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached watchdog-4.0.1-py3-none-win_amd64.whl (83 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toolz, toml, smmap, pyarrow, mdurl, click, blinker, pydeck, markdown-it-py, gitdb, rich, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.3.0 blinker-1.8.2 click-8.1.7 gitdb-4.0.11 gitpython-3.1.43 markdown-it-py-3.0.0 mdurl-0.1.2 pyarrow-17.0.0 pydeck-0.9.1 rich-13.7.1 smmap-5.0.1 streamlit-1.37.1 toml-0.10.2 toolz-0.12.1 watchdog-4.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "st.title(\"Breast Cancer Prediction App\")\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train = pd.read_csv('train_features.csv')\n",
    "X_test = pd.read_csv('test_features.csv')\n",
    "y_train = pd.read_csv('train_labels.csv')\n",
    "y_test = pd.read_csv('test_labels.csv')\n",
    "\n",
    "# Initialize and train the ANN model\n",
    "trained_model = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, max_iter=1000)\n",
    "trained_model.fit(X_train, y_train)\n",
    "\n",
    "# User input\n",
    "st.sidebar.header(\"Enter Features\")\n",
    "user_input = st.sidebar.text_input(\"Enter feature values separated by commas (e.g., 0.1,0.2,0.3,...):\")\n",
    "\n",
    "if user_input:\n",
    "    user_data = pd.DataFrame([user_input.split(\",\")], columns=X_train.columns)\n",
    "    prediction = trained_model.predict(user_data)\n",
    "    st.write(f\"Prediction: {'Malignant' if prediction[0] == 1 else 'Benign'}\")\n",
    "\n",
    "# Model evaluation\n",
    "y_test_pred = trained_model.predict(X_test)\n",
    "st.write(f\"Accuracy on Test Data: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
